{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": false,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": true,
    "force_recompute_fp8_weight_in_bwd": false,
    "quantize_optimizer": true,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        86.45802559054047,
        2659.881708446987,
        2662.234073978261,
        2662.2217155364765,
        2663.866716936983,
        2666.381734257526,
        2664.9319572923964,
        2666.8578126414477,
        2575.004156825195,
        2651.5399626388075,
        2650.8377687844863,
        2656.5444653660143,
        2655.5463756604445,
        2661.556202522108,
        2650.9382997280595,
        2653.65395794068,
        2652.149514715442,
        2658.6409986965914,
        2657.2000858483693,
        2654.5078293653487,
        2654.9703376376006
    ],
    "training_tokens_per_second": [
        3.82053279876709,
        910.7627563476562,
        1085.822265625,
        865.6119995117188,
        546.0406494140625,
        1170.578125,
        1065.5823974609375,
        295.8545227050781,
        1018.5599975585938,
        595.690185546875,
        758.62109375,
        399.64910888671875,
        1041.7314453125,
        194.41836547851562,
        884.5953369140625,
        674.1680297851562,
        927.21630859375,
        346.86956787109375,
        748.8944702148438,
        852.8643188476562,
        886.3297119140625
    ],
    "mfus": [
        0.45057136705415857,
        13.861830979730772,
        13.87409020663305,
        13.87402580127598,
        13.88259863791861,
        13.895705515904107,
        13.888150080944307,
        13.898186572888735,
        13.419496168066681,
        13.818358418488048,
        13.814698972847028,
        13.844439116258117,
        13.83923762524546,
        13.870557515866636,
        13.815222884471977,
        13.829375391714127,
        13.821535066469355,
        13.855365087356585,
        13.847855847267017,
        13.83382529688457,
        13.836235633959456
    ],
    "tflops": [
        4.456150820165628,
        137.09350838953733,
        137.21475214360086,
        137.21411517461945,
        137.29890052901507,
        137.42852755229163,
        137.3538043005392,
        137.4530652058696,
        132.7188171021795,
        136.6635647588468,
        136.62737284145712,
        136.92150285979278,
        136.8700601136776,
        137.17981383192102,
        136.63255432742787,
        136.77252262405273,
        136.6949818073819,
        137.0295607139566,
        136.9552943294708,
        136.8165321861884,
        136.84037041985903
    ],
    "memory_summaries": [
        62483327488,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040
    ],
    "training_start": 1013640.667338361,
    "training_end": 1013841.204187537,
    "training_duration": 200.5368491759291
}
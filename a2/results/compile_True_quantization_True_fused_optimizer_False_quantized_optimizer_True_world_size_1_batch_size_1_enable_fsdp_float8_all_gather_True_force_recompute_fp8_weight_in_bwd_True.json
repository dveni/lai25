{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": true,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": true,
    "force_recompute_fp8_weight_in_bwd": true,
    "quantize_optimizer": true,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        74.9398244872677,
        4229.52628549701,
        4274.234165339337,
        4296.678111120984,
        4276.498458636797,
        4254.586124857243,
        4235.092113863272,
        4270.2483071857305,
        4285.498414433317,
        4274.788861729004,
        4247.097858083494,
        4265.209111447286,
        4258.947678867288,
        4249.070245160242,
        4244.505204801179,
        4254.002508312778,
        4213.463389047961,
        4226.98116346602,
        3982.932070265604,
        4212.8283267538845,
        4202.668407655595
    ],
    "training_tokens_per_second": [
        3.311549663543701,
        1448.2203369140625,
        1743.294921875,
        1397.0498046875,
        876.5986328125,
        1867.821533203125,
        1693.4163818359375,
        473.73065185546875,
        1695.1573486328125,
        960.3663940429688,
        1215.44140625,
        641.6557006835938,
        1670.721923828125,
        310.38128662109375,
        1416.3548583984375,
        1080.740966796875,
        1473.0662841796875,
        551.4888916015625,
        1122.533447265625,
        1353.5357666015625,
        1403.0098876953125
    ],
    "mfus": [
        0.39054487926822706,
        22.04194957531382,
        22.274942295203722,
        22.391907715867138,
        22.286742538379293,
        22.172547585175536,
        22.070955591570225,
        22.254170209039508,
        22.333645325702584,
        22.277833065712127,
        22.13352288418256,
        22.227908710500582,
        22.19527759016193,
        22.143801873732226,
        22.120011410542823,
        22.16950609883024,
        21.958238651284933,
        22.028685808243154,
        20.756837037691653,
        21.95492905817253,
        21.901981184264837
    ],
    "tflops": [
        3.8624888559627655,
        217.9948812998537,
        220.29917929956477,
        221.455967309926,
        220.4158837045712,
        219.28649561738607,
        218.2817508006295,
        220.09374336740072,
        220.87975227119853,
        220.3277690198929,
        218.9005413245655,
        219.83401714685075,
        219.5112953667015,
        219.0022005312117,
        218.76691285026854,
        219.2564153174311,
        217.166980261208,
        217.86370264352482,
        205.28511830277043,
        217.13424838532632,
        216.61059391237924
    ],
    "memory_summaries": [
        59379106304,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240,
        65822090240
    ],
    "training_start": 1014695.47324214,
    "training_end": 1014846.187261392,
    "training_duration": 150.71401925198734
}
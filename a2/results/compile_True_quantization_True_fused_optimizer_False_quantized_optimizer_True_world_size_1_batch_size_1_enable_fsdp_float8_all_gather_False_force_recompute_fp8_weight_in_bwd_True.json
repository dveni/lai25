{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": true,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": false,
    "force_recompute_fp8_weight_in_bwd": true,
    "quantize_optimizer": true,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        76.98871874830182,
        4142.358786897595,
        4017.7740028893177,
        4016.1574587620876,
        4010.611391472769,
        4020.7342425196784,
        4008.885623715552,
        4016.5705887474296,
        4010.147161227407,
        4015.2559083891415,
        4016.948398065357,
        4020.8974949268345,
        4028.8227036133108,
        4020.3890015389275,
        4017.857048544,
        4016.9771143567664,
        4018.7874080262927,
        4018.958677813684,
        4009.390281824352,
        4020.2651871665626,
        4020.004743343831
    ],
    "training_tokens_per_second": [
        3.4020893573760986,
        1418.3736572265625,
        1638.694580078125,
        1305.8394775390625,
        822.0969848632812,
        1765.1573486328125,
        1602.967041015625,
        445.58831787109375,
        1586.240234375,
        902.0601196289062,
        1149.576904296875,
        604.9016723632812,
        1580.4473876953125,
        293.6768798828125,
        1340.724365234375,
        1020.5240478515625,
        1405.0057373046875,
        524.3485107421875,
        1129.9903564453125,
        1291.6671142578125,
        1342.0299072265625
    ],
    "mfus": [
        0.40122258190876214,
        21.58768082769478,
        20.93841390237075,
        20.929989369282765,
        20.901086336819855,
        20.953841032564267,
        20.892092590637517,
        20.932142374061616,
        20.898667025774387,
        20.925290987828504,
        20.934111307075085,
        20.954691813735412,
        20.99599361409073,
        20.95204182769465,
        20.938846690349685,
        20.93426096048885,
        20.943695208933416,
        20.944587772252007,
        20.89472258932675,
        20.951396575728314,
        20.950039286703408
    ],
    "tflops": [
        3.968091335077658,
        213.50216338590138,
        207.08091349444672,
        206.99759486220654,
        206.71174387114834,
        207.2334878120606,
        206.62279572140503,
        207.0188880794694,
        206.68781688490864,
        206.95112786962392,
        207.0383608269726,
        207.24190203784326,
        207.65037684335732,
        207.21569367590007,
        207.0851937675584,
        207.03984089923472,
        207.1331456163515,
        207.14197306757237,
        206.64880640844157,
        207.20931213395306,
        207.19588854549673
    ],
    "memory_summaries": [
        67298501632,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184,
        83691037184
    ],
    "training_start": 1013099.790048362,
    "training_end": 1013254.174370127,
    "training_duration": 154.38432176504284
}
{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": true,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": true,
    "force_recompute_fp8_weight_in_bwd": true,
    "quantize_optimizer": false,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        386.098853408029,
        3908.7373629901113,
        3765.963170619708,
        3832.7938524062497,
        3836.731647275722,
        3836.5594078712556,
        3829.7735712390304,
        3837.5069911451974,
        3836.761092142601,
        3839.7895521433884,
        3837.023821358169,
        3852.157544469708,
        3840.3979789406917,
        3849.378119553039,
        3832.143899306435,
        3843.1030374068664,
        3833.66275371642,
        3716.2963762759096,
        3834.9340770443137,
        3845.9933607113685,
        3831.1369799727627
    ],
    "training_tokens_per_second": [
        17.061498641967773,
        1338.3798828125,
        1535.99072265625,
        1246.2193603515625,
        786.4550170898438,
        1684.302001953125,
        1531.348388671875,
        425.7234191894531,
        1517.65625,
        862.6401977539062,
        1098.0858154296875,
        579.5164794921875,
        1506.531005859375,
        281.18505859375,
        1278.7535400390625,
        976.350830078125,
        1340.284423828125,
        484.8605651855469,
        1080.822265625,
        1235.675537109375,
        1278.9786376953125
    ],
    "mfus": [
        2.0121334833851754,
        20.37017529684154,
        19.626115244614017,
        19.97439976126875,
        19.99492136820342,
        19.994023751777405,
        19.958659727823537,
        19.998962031228288,
        19.995074818549202,
        20.010857475547244,
        19.996444017776398,
        20.075312604751524,
        20.01402825919562,
        20.0608277807485,
        19.97101256552024,
        20.028125526427214,
        19.97892799388202,
        19.367279407549383,
        19.985553427274752,
        20.043188291435353,
        19.965765059373908
    ],
    "tflops": [
        19.900000150679382,
        201.46103368576286,
        194.10227976923264,
        197.5468136389479,
        197.7497723315318,
        197.74089490507853,
        197.39114470817478,
        197.78973448884776,
        197.7512899554516,
        197.90738043316225,
        197.76483133580857,
        198.54484166099257,
        197.9387394834447,
        198.40158675160268,
        197.51331427299516,
        198.07816145636517,
        197.59159785949322,
        191.5423933406634,
        197.65712339574728,
        198.22713220229565,
        197.46141643720796
    ],
    "memory_summaries": [
        66643518976,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312,
        81676429312
    ],
    "training_start": 1014224.771612545,
    "training_end": 1014341.441326811,
    "training_duration": 116.66971426596865
}
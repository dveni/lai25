{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": true,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": true,
    "force_recompute_fp8_weight_in_bwd": false,
    "quantize_optimizer": true,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        76.08479952864523,
        4397.321115133803,
        4432.441700209975,
        4457.749305354944,
        4435.363536245912,
        4439.849227435146,
        4451.69203474532,
        4440.818237862373,
        4445.324146836,
        4439.060930919235,
        4429.113964189951,
        4457.797524435645,
        4436.805368989674,
        4435.8960924945295,
        4439.239191860266,
        4416.674002869718,
        4450.492949282206,
        4435.52408765537,
        4429.260485846036,
        4443.310596014104,
        4181.071013475619
    ],
    "training_tokens_per_second": [
        3.3621459007263184,
        1505.6744384765625,
        1807.821533203125,
        1449.4215087890625,
        909.162841796875,
        1949.154541015625,
        1780.0247802734375,
        492.6532897949219,
        1758.37744140625,
        997.271484375,
        1267.5311279296875,
        670.628662109375,
        1740.492919921875,
        324.0283508300781,
        1481.3359375,
        1122.068115234375,
        1555.93408203125,
        578.697265625,
        1248.3248291015625,
        1427.587158203125,
        1395.7999267578125
    ],
    "mfus": [
        0.3965118553368179,
        22.916403337791845,
        23.099432384793868,
        23.231321612764894,
        23.1146593767131,
        23.13803631595629,
        23.199754471593742,
        23.14308626186823,
        23.166568565011303,
        23.13392815090866,
        23.08209006685986,
        23.23157290391989,
        23.122173410788978,
        23.117434765062924,
        23.134857148249786,
        23.01725987510064,
        23.19350550196207,
        23.115496081779494,
        23.08285365661841,
        23.156075052809772,
        21.789427521906582
    ],
    "tflops": [
        3.921502249281129,
        226.6432290107614,
        228.45338628561134,
        229.7577707502448,
        228.60398123569257,
        228.83517916480767,
        229.4455717240621,
        228.8851231298768,
        229.11736310796178,
        228.79454941248665,
        228.281870761244,
        229.7602560197677,
        228.678295032703,
        228.63142982647236,
        228.8037371961904,
        227.6407001647453,
        229.3837694144048,
        228.61225624879918,
        228.28942266395606,
        229.01358227228863,
        215.4974381916561
    ],
    "memory_summaries": [
        59379106304,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872,
        71896655872
    ],
    "training_start": 1014200.106759409,
    "training_end": 1014345.897165511,
    "training_duration": 145.79040610208176
}
{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": false,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": true,
    "force_recompute_fp8_weight_in_bwd": true,
    "quantize_optimizer": true,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        84.0803763738101,
        2477.6722783508167,
        2475.5734900751363,
        2479.7136100705106,
        2390.9115351238224,
        2469.04441829914,
        2475.582231853743,
        2478.6689652046502,
        2475.01811672063,
        2479.0181772170627,
        2473.570518910164,
        2470.4395967419327,
        2473.1284994284138,
        2384.7070464404974,
        2445.9449448432892,
        2441.7086774387985,
        2435.3863564155986,
        2435.9983771010957,
        2441.2539565367597,
        2430.5850176956683,
        2410.502889631463
    ],
    "training_tokens_per_second": [
        3.715466022491455,
        848.3729248046875,
        1009.6906127929688,
        806.2702026367188,
        490.09014892578125,
        1083.9442138671875,
        989.8702392578125,
        274.97735595703125,
        979.0098876953125,
        556.9317626953125,
        707.8904418945312,
        371.6515808105469,
        970.1715698242188,
        174.19540405273438,
        816.1907958984375,
        620.32275390625,
        851.433837890625,
        317.8216552734375,
        688.0330810546875,
        780.92041015625,
        804.7171630859375
    ],
    "mfus": [
        0.43818037558008693,
        12.912256299441367,
        12.901318576817339,
        12.922894590302986,
        12.460107335647557,
        12.867292669151606,
        12.901364134128073,
        12.917450479567382,
        12.89842427834295,
        12.919270379255694,
        12.890880199930898,
        12.874563566838198,
        12.88857663908971,
        12.427772975374776,
        12.746911001143994,
        12.724833920588303,
        12.691885483390934,
        12.695074996395036,
        12.722464166975954,
        12.666863563957167,
        12.562206629757693
    ],
    "tflops": [
        4.33360391448706,
        127.70221480147512,
        127.59404072472348,
        127.80742749809654,
        123.23046154955435,
        127.25752449790937,
        127.59449128652665,
        127.75358524292139,
        127.56541611281177,
        127.77158405083881,
        127.49080517731657,
        127.32943367602977,
        127.46802296059724,
        122.91067472645655,
        126.06694980131411,
        125.84860747461833,
        125.52274743073635,
        125.55429171434689,
        125.82517061139218,
        125.27528064753639,
        124.24022356830358
    ],
    "memory_summaries": [
        62483327488,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040,
        78875863040
    ],
    "training_start": 1014428.414385386,
    "training_end": 1014642.876393442,
    "training_duration": 214.462008055998
}
{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": true,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": false,
    "force_recompute_fp8_weight_in_bwd": false,
    "quantize_optimizer": true,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        75.27709909876769,
        4135.176310959603,
        3990.0951793936174,
        4006.7644655527674,
        4009.564896148698,
        3995.945638683289,
        4007.598852847813,
        3997.341894915323,
        4012.988104956116,
        4007.301681666423,
        4004.7064687596903,
        4009.255030072139,
        4006.577498842276,
        4004.919457724534,
        4016.98427785492,
        4007.032859967352,
        4007.6900010071463,
        4003.773255209634,
        4001.4397438308497,
        4001.0306294855723,
        4005.5122028290066
    ],
    "training_tokens_per_second": [
        3.326453685760498,
        1415.914306640625,
        1627.405517578125,
        1302.785400390625,
        821.8825073242188,
        1754.274658203125,
        1602.4525146484375,
        443.45513916015625,
        1587.3641357421875,
        900.273193359375,
        1146.073486328125,
        603.150146484375,
        1571.7208251953125,
        292.5468444824219,
        1340.43310546875,
        1017.9976196289062,
        1401.1259765625,
        522.3673095703125,
        1127.74951171875,
        1285.4874267578125,
        1337.1917724609375
    ],
    "mfus": [
        0.392302567831414,
        21.550249739254927,
        20.794167197039176,
        20.881038288545653,
        20.89563258252045,
        20.82465655209947,
        20.88538665321872,
        20.83193306662693,
        20.91347245176954,
        20.8838379615324,
        20.870313148547183,
        20.894017732068274,
        20.88006392155353,
        20.871423129123325,
        20.934298292675585,
        20.882437011653924,
        20.88586166696643,
        20.865449756142255,
        20.85328878664528,
        20.851156709159422,
        20.8745121884699
    ],
    "tflops": [
        3.879872395852684,
        213.13196992123125,
        205.65431357871745,
        206.5134686737165,
        206.65780624112725,
        205.95585330026375,
        206.55647400033317,
        206.02781802894037,
        206.8342425480008,
        206.54115743955543,
        206.40739703913167,
        206.64183537015526,
        206.50383218416437,
        206.41837474702967,
        207.04021011456152,
        206.5273020452573,
        206.561171886298,
        206.35929808824687,
        206.23902609992177,
        206.2179398535867,
        206.4489255439673
    ],
    "memory_summaries": [
        74277708800,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352,
        90670244352
    ],
    "training_start": 1012596.616174848,
    "training_end": 1012752.490175791,
    "training_duration": 155.8740009429166
}
{
    "dataset": "/capstor/store/cscs/ethz/large-sc/datasets/train_data.parquet",
    "tokenizer_name_or_path": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit",
    "sequence_length": 4096,
    "batch_size": 1,
    "fused_optimizer": false,
    "learning_rate": 5e-05,
    "lr_warmup_steps": 100,
    "training_steps": 100,
    "logging_frequency": 5,
    "profile": false,
    "profile_step_start": 10,
    "profile_step_end": 12,
    "grad_max_norm": 1,
    "model_dtype": "bf16",
    "compile": true,
    "quantization": false,
    "quantization_torchao": true,
    "enable_fsdp_float8_all_gather": true,
    "force_recompute_fp8_weight_in_bwd": false,
    "quantize_optimizer": false,
    "train_steps": [
        1,
        5,
        10,
        15,
        20,
        25,
        30,
        35,
        40,
        45,
        50,
        55,
        60,
        65,
        70,
        75,
        80,
        85,
        90,
        95,
        100
    ],
    "losses": [
        11.783501625061035,
        11.7835054397583,
        11.783502578735352,
        11.783504486083984,
        11.783503532409668,
        11.783485412597656,
        11.783506393432617,
        11.783501625061035,
        11.783500671386719,
        11.783503532409668,
        11.783504486083984,
        11.78349781036377,
        11.7835054397583,
        11.783499717712402,
        11.78349781036377,
        11.783499717712402,
        11.78350830078125,
        11.783500671386719,
        11.783492088317871,
        11.783499717712402,
        11.7835054397583
    ],
    "tokens_per_second": [
        382.2740790035011,
        3807.9486806772275,
        3752.6831361825302,
        3740.9341117067374,
        3733.396938220041,
        3743.2595983141237,
        3739.4710825279412,
        3743.651348410789,
        3743.6853554268196,
        3748.6610335792952,
        3757.2296363110195,
        3743.9130427168116,
        3746.5581243113006,
        3744.58290679686,
        3744.751566780371,
        3739.472022074129,
        3741.724956685591,
        3751.6985469551237,
        3756.3456290016347,
        3740.212771017327,
        3739.5369304380124
    ],
    "training_tokens_per_second": [
        16.89248275756836,
        1303.869140625,
        1530.5743408203125,
        1216.3515625,
        765.2734375,
        1643.342041015625,
        1495.24072265625,
        415.3113098144531,
        1480.839599609375,
        842.16748046875,
        1075.2501220703125,
        563.2322387695312,
        1469.7191162109375,
        273.53009033203125,
        1249.5914306640625,
        950.0231323242188,
        1308.14208984375,
        489.4794006347656,
        1058.6732177734375,
        1201.689453125,
        1248.3990478515625
    ],
    "mfus": [
        1.9922008765467596,
        19.844920480262985,
        19.556907056825604,
        19.49567764540368,
        19.4563980696971,
        19.507796794234565,
        19.488053147242542,
        19.50983837886933,
        19.510015604610928,
        19.535946084654505,
        19.580600898596956,
        19.511202184720894,
        19.524986885699875,
        19.514693145475853,
        19.515572107941384,
        19.488058043637153,
        19.49979909162936,
        19.5517759228314,
        19.575993941878306,
        19.491918417057676,
        19.488396310097073
    ],
    "tflops": [
        19.702866669047452,
        196.26626354980093,
        193.41781079200524,
        192.8122519130424,
        192.4237769093043,
        192.93211029497982,
        192.73684562622879,
        192.95230156701768,
        192.9540543296021,
        193.21050677723306,
        193.6521428871239,
        192.96578960688962,
        193.10212029957174,
        193.00031520875618,
        193.00900814754027,
        192.73689405157143,
        192.85301301621436,
        193.36706387680258,
        193.60658008517643,
        192.7750731447004,
        192.74023950686004
    ],
    "memory_summaries": [
        66643518976,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944,
        87750994944
    ],
    "training_start": 1013461.006129624,
    "training_end": 1013580.152245959,
    "training_duration": 119.14611633506138
}